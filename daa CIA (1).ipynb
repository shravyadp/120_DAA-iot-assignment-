{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc92e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "import tensorflow as tf\n",
    "from   torch.optim.lr_scheduler import ExponentialLR as ExponentialLR\n",
    "#from torch.optim.lr_scheduler import ExponentialLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Downloads\\MLT\\NN\\Bank_Personal_Loan_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd5f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['ID'] , inplace = True , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb9c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(['Personal Loan'] , axis = 1).values\n",
    "y = data['Personal Loan'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80080dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x , dtype = torch.float64)\n",
    "y = torch.tensor(y)\n",
    "y = y.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b67c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ee938",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self , input_size , hidden1 , hidden2 ,  output_size):\n",
    "        super().__init__()\n",
    "        self.input_ = nn.Linear(input_size , hidden1)\n",
    "        self.hidden1_ = nn.Linear(hidden1 , hidden2)\n",
    "        self.out = nn.Linear(hidden2 , output_size)\n",
    "    def forward(self , x):\n",
    "        x = f.relu(self.input_(x))\n",
    "        x = torch.sigmoid(self.hidden1_(x))\n",
    "        x = self.out(x)\n",
    "        x = f.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ff2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a2f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(12 , 10 , 8 , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c494378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd506f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam( model.parameters(), lr=100)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1f6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d911f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TensorDataset(x , y)\n",
    "data = DataLoader(data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad58b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    final_losses = []\n",
    "    for i in range(n_epochs):\n",
    "        y_pred = model(x.float())\n",
    "        loss = loss_function(y_pred , y)\n",
    "        final_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        if (i%10 == 0):\n",
    "            print(\"Epoch {} has loss of {}\".format(i , loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab9b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1 , n_epochs+1) , final_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52a4b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for i , data in enumerate(x):\n",
    "        y_pred = (model(data.float()))\n",
    "        predictions.append(y_pred.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c526d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y , predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23344fe1",
   "metadata": {},
   "source": [
    "#GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c83b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726cb977",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#intializing the population\n",
    "import random\n",
    "populations = ([[random.randint(0,1) for  i in range(6)] for j in range(4)])\n",
    "print(populations)\n",
    "\n",
    "best = -100000\n",
    "parents=[]\n",
    "new_population =[]\n",
    "\n",
    "#fitness score\n",
    "\n",
    "def fitness_score():\n",
    "    global populations,best\n",
    "    fit_value=[]\n",
    "    fit_score =[]\n",
    "    chromosome_value = 0\n",
    "    for i in range(4):\n",
    "        for j in range(5,0,-1):\n",
    "            chromosome_value += populations[i][j](2*(5-j))\n",
    "            if populations[i][0] ==1:\n",
    "                chromosome_value = -1*chromosome_value\n",
    "            else:\n",
    "                chromosome_value\n",
    "        print(chromosome_value)   \n",
    "        fit_value.append(-(chromosome_value**2)+5)\n",
    "    \n",
    "    fit_value,populations = zip(*sorted(zip(fit_value,populations),reverse= True))\n",
    "    print(fit_value)\n",
    "    print(populations)\n",
    "    best = fit_value[0]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def select_parents():\n",
    "    global parents\n",
    "    parents = populations[0:2]\n",
    "    print(parents)\n",
    "\n",
    "\n",
    "\n",
    "def crossover():\n",
    "    global parents\n",
    "    cross_point = random.randint(0,5)\n",
    "    parents = parents + tuple([(parents[0][0:cross_point+1]+parents[1][cross_point+1:6])])\n",
    "    parents = parents + tuple([(parents[1][0:cross_point+1]+parents[0][cross_point+1:6])])\n",
    "    print(parents)\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "def mutation():\n",
    "    global populations,parents\n",
    "    mute = random.randint(0, 29)\n",
    "    if mute == 10:\n",
    "        x= random.randint(0, 4)\n",
    "        y = random.randint(0,5)\n",
    "        parents[x][y] = 1 - parents[x][y]\n",
    "    populations = parents\n",
    "    print(populations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    fitness_score()\n",
    "    select_parents()\n",
    "    crossover() \n",
    "    mutation()\n",
    "print(\"the best score is\",best) \n",
    "print(\"Sequence is\",populations[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94652b8",
   "metadata": {},
   "source": [
    "#AN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf397d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "NV = 10\n",
    "\n",
    "def formPheremoneMatrix(graph):\n",
    "    \n",
    "    nv = len(graph)\n",
    "    pheremones = np.ones((nv,nv))\n",
    "        \n",
    "    return pheremones\n",
    "           \n",
    "def chooseNextVertex(graph, pheremones, currPos):\n",
    "    graph = 1/graph\n",
    "    denominator = np.dot(graph[currPos], pheremones[currPos])\n",
    "    numerator = graph[currPos] * pheremones[currPos]\n",
    "    \n",
    "    probabilities = numerator/denominator\n",
    "    \n",
    "    \n",
    "    rouletteWheel = np.cumsum(probabilities)\n",
    "    \n",
    "    rouletteBall = np.random.random()\n",
    "    \n",
    "    nextVertex = np.where(rouletteWheel >= rouletteBall)[0][0]\n",
    "    \n",
    "    return nextVertex\n",
    "\n",
    "def traverse(graph, pheremones, start, end):\n",
    "    curr = start\n",
    "    path = [curr]\n",
    "    cost = 0\n",
    "    prev = start\n",
    "    \n",
    "    while curr != end:\n",
    "        nextVertex = chooseNextVertex(graph, pheremones, curr)\n",
    "        \n",
    "        while nextVertex == prev:\n",
    "            nextVertex = chooseNextVertex(graph, pheremones, curr)\n",
    "        \n",
    "        cost += graph[curr][nextVertex]\n",
    "        path += [nextVertex]\n",
    "        prev = curr\n",
    "        curr = nextVertex\n",
    "        \n",
    "    \n",
    "    return path, cost\n",
    "    \n",
    "    \n",
    "\n",
    "def releaseGeneration(graph, pheremones, start, end, size = 10):\n",
    "    paths = []\n",
    "    costs = []\n",
    "    for i in range(size):\n",
    "        p, c = traverse(graph, pheremones, start, end)\n",
    "        paths += [p]\n",
    "        costs += [c]\n",
    "    costs = np.array(costs)    \n",
    "    \n",
    "    return paths, costs\n",
    "    \n",
    "def updatePheremones(paths, costs, pheremones, decay = 0):\n",
    "    pheremones = (1-decay)*pheremones\n",
    "    \n",
    "    costs = 1/costs\n",
    "    for p in range(len(paths)):\n",
    "        path = paths[p]\n",
    "        for i in range(len(path) - 1):\n",
    "            pheremones[path[i]][path[i+1]] += costs[p]\n",
    "    \n",
    "    return pheremones\n",
    "            \n",
    "\n",
    "def generateProblem(size, density):\n",
    "    graph = np.full((size, size), np.inf)\n",
    "    \n",
    "    for i in range(len(graph)):\n",
    "        for j in range(i, len(graph)):\n",
    "            if np.random.random() < density:\n",
    "                if i!=j:\n",
    "                    w = np.random.randint(1,20)\n",
    "                    graph[i][j] = w\n",
    "                    graph[j][i] = w\n",
    "                    \n",
    "    return graph\n",
    "#%%\n",
    "graph = generateProblem(NV, 0.5)\n",
    "\n",
    "#%%\n",
    "ph = formPheremoneMatrix(graph)\n",
    "print(graph)\n",
    "\n",
    "#%%\n",
    "gen = 0\n",
    "SIZE = 100\n",
    "\n",
    "for i in range(100):\n",
    "    p,c = releaseGeneration(graph, ph, 0, 7, SIZE)\n",
    "    ph = updatePheremones(p, c, ph, decay = 0)\n",
    "    gen += 1\n",
    "\n",
    "    print(\"--\",gen,\"--\")   \n",
    "    c = np.array(c)\n",
    "    unique, counts = np.unique(c, return_counts=True)\n",
    "    print(unique)\n",
    "    print(counts)\n",
    "    \n",
    "    if len(np.where(counts > SIZE//2)[0]) == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63ec931",
   "metadata": {},
   "source": [
    "#ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ea6f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import pygad\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from pygad.kerasga import KerasGA\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16366b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e1a47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8a3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target',axis = 1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6caec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26747aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=42,\n",
    "                                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c4db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np_utils.to_categorical(y_train,num_classes=2)\n",
    "y_test=np_utils.to_categorical(y_test,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc214462",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([tf.keras.layers.Dense(12,input_shape = (12,),activation = 'relu'),\n",
    "                    tf.keras.layers.Dense(8,activation = 'relu'),\n",
    "                    tf.keras.layers.Dense(16, activation = 'relu'),\n",
    "                    tf.keras.layers.Dense(8,activation = 'relu'),\n",
    "                    tf.keras.layers.Dense(2,activation = 'softmax')\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aaedf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be99451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_func(solution, sol_idx):\n",
    "    global X_train, y_train, keras_ga, model\n",
    "    \n",
    "    model_weights_matrix = pygad.kerasga.model_weights_as_matrix(model = model,weights_vector = solution)\n",
    "    \n",
    "    model.set_weights(weights = model_weights_matrix)\n",
    "    \n",
    "    predictions = model.predict(X_train)\n",
    "    \n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    \n",
    "    solution_fitness = 1.0/(loss(y_train,predictions).numpy() + 0.0000000001)\n",
    "    \n",
    "    return solution_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd3e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceptance_function(population, fitness):\n",
    "    belief_space = population[fitness.index(max(fitness))]\n",
    "    return belief_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def influence_function(belief_space,population):\n",
    "    sim = cosine_similarity(belief_space.reshape(1,-1),population)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bce753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent_selection(sim,population):\n",
    "    # Get the indices of the two highest values using argsort\n",
    "    highest_indices = np.argsort(sim[0])[-2:]\n",
    "\n",
    "    # Get the values at the indices using fancy indexing\n",
    "    highest_values = sim[0][highest_indices]\n",
    "    parent_1 = population[highest_indices[0]]\n",
    "    parent_2 = population[highest_indices[1]]\n",
    "    return parent_1,parent_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    \"\"\"\n",
    "    Performs a crossover operation between two parents, producing two new children.\n",
    "\n",
    "    Args:\n",
    "        parent1 (numpy.ndarray): The first parent.\n",
    "        parent2 (numpy.ndarray): The second parent.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of two children produced by crossover.\n",
    "    \"\"\"\n",
    "    # Determine the length of the parents and the crossover point.\n",
    "    length = parent1.shape[0]\n",
    "    crossover_point = np.random.randint(1, length - 1)\n",
    "\n",
    "    # Create the first child by combining the parents.\n",
    "    child1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "\n",
    "    # Create the second child by combining the parents in reverse order.\n",
    "    child2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n",
    "\n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd987d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(array):\n",
    "    \"\"\"\n",
    "    Adds a randomly generated value to 15% of the elements in a numpy array.\n",
    "\n",
    "    Args:\n",
    "        array (numpy.ndarray): The input array.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array with mutations applied.\n",
    "    \"\"\"\n",
    "    # Determine the number of elements to mutate.\n",
    "    num_mutations = int(0.15 * array.size)\n",
    "\n",
    "    # Generate random indices for the elements to mutate.\n",
    "    mutation_indices = np.random.choice(array.size, size=num_mutations, replace=False)\n",
    "\n",
    "    # Add a random value to the selected elements.\n",
    "    array[mutation_indices] += np.random.randn(num_mutations)\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07971f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_population(population,child1, child2):\n",
    "    population = np.vstack((population, child1))\n",
    "    population = np.vstack((population,child2))\n",
    "# Calculate the fitness of each solution in the population.\n",
    "    fitness_values = np.zeros((population.shape[0],))\n",
    "    for i in range(population.shape[0]):\n",
    "        fitness_values[i] = fitness_func(population[i], i)\n",
    "\n",
    "    # Sort the population by fitness.\n",
    "    sorted_indices = np.argsort(fitness_values)\n",
    "    sorted_population = population[sorted_indices]\n",
    "\n",
    "    # Return the top 10 elements.\n",
    "    return sorted_population[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cultural_algorithm(population):\n",
    "    \n",
    "    fitness = []\n",
    "    for idx, solution in enumerate(population):\n",
    "        fitness.append(fitness_func(solution,idx))\n",
    "    \n",
    "    belief_space = acceptance_function(population,fitness)\n",
    "    similarity_score = influence_function(belief_space,population)\n",
    "    parent1,parent2 = parent_selection(sim,population)\n",
    "    child1,child2 = crossover(parent1, parent2)\n",
    "    child1 = mutation(child1)\n",
    "    child2 = mutation(child2)\n",
    "    population = prune_population(population,child1, child2)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_final_weights(population):\n",
    "    fitness = []\n",
    "    for idx, solution in enumerate(population):\n",
    "        fitness.append(fitness_func(solution,idx))\n",
    "    model_weights_matrix = pygad.kerasga.model_weights_as_matrix(model = model,weights_vector = population[fitness.index(max(fitness))])\n",
    "    \n",
    "    model.set_weights(weights = model_weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4112e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shapes of the model's weights\n",
    "weights_shapes = [w.shape for w in model.get_weights()]\n",
    "\n",
    "# Compute the total number of weights\n",
    "num_weights = np.sum([np.prod(s) for s in weights_shapes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b4a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "population = np.random.uniform(size = (10,num_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48eb2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    population = cultural_algorithm(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
